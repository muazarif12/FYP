 You're not going to want to miss this episode of the AI show where we do text analytics for health. I teared up a little because I did research in this area many moons ago and it is so much better now. Hopefully you'll tune in. We'll see you then. Hello and welcome to this episode of the AI show. We're going to learn a little bit about text analytics but for a specific use case for health. I've got Ashley Yeo, Senior Program Manager in the Cognitive Services team. He does text analytics. Why don't you tell us what you do and what you work on my friend. Hi Seth. Happy to be here and to share with you and your audience about text analytics specifically for the healthcare domain. We released and announced back in July text analytics for health as a preview offering for our customers in the healthcare space for obvious reasons because of the pandemic. But we put out this product early in January this year and we make the announcement in July because of the demand for it. So text analytics for health is a product that utilizes NLP natural language processing techniques to process documents in the healthcare space such as doctor's notes, discharge summaries, research articles, those kind of documents in unstructured form. So text analytics for health. I will explain a little bit in a demo about the different features that this text analytics for health API provides. This is really cool but for those that maybe don't know about text analytics in general, can you give us like maybe a minute blurb on what text analytics is and then let's dive into how we've repurposed text analytics to do some stuff for health as you described. So let's start with text analytics. Sure. Text analytics provides four features, four functions if you will, all of them natural language processing techniques to extract information from unstructured text. information such as sentiment analysis being able to define or detect the kind of sentiment in each of those unstructured text, especially from social media, text information, text information. Also, we also recently released something called opinion mining that can tag the sentiment to each of the aspects within that text. Text analytics also provide language detection for obvious reasons and we also do key phrase extractions within a blurb like in news articles, also research papers, providing the pulling out the key phrases in those kind of contexts. Lastly, the fourth feature is name entity recognition which is really key in this healthcare feature. Name entity recognition identifies an entity and assign them to a category. For instance, it's a person name, whether it's an organization, whether it's a date, and also things like email addresses. So this is cool. So how did you all repurpose this stuff for health? Let's talk about text analytics specifically for health. Sure. It's actually not repurposed. Actually, it's an extension of what the text analytics has been offered to our customers. We partnered with our team in Microsoft Research Health Next. We started from scratch. We actually took a set of documents from the healthcare space and asked the subject matter experts like physicians, nurses, researchers to annotate those documents. To pull the entities, relationships, they are more relevant and critical to the healthcare space. So we started from scratch, built that, and then using the latest research for an NLP from Microsoft Research and build the models for that. That's really cool. I love how you say it's an extension because you can still use text analytics for the other things you mentioned, but now we're extending it to do specific stuff. Why don't we talk a little about the features, maybe some of the use cases, and when people can take a look at it? Sure. Why don't I just go straight to the demo? So what you see here is a web interface visualization tool that is provided in the container that we recently released for public preview. This visualization tool will allow us to identify the features that we built into text analytics for health. Alongside this feature, this is, by the way, it's included in the demo, this demo app. It's included in the container. I beg your pardon. So I will select an example text here as I just take talking about a patient history. And what you see here is the output from the API. We send this text into the API. It returns as a JSON, for those who understand what JSON is, and it pulls out four things. So the user is able to identify entities related to eight different categories. For instance, diagnosis. We have body structure, symptoms, and the medication as well. So they all fall into eight categories. Each category has their own entity type. So you see those being highlighted in the JSON. But for visualization and simplicity, ease of use, we provide this UI visualization tool. Also, besides entity recognition, we also extract things that will also link the entity to what we call concepts of vocabularies that are provided in the healthcare space. Specifically, if you, I cannot move it down. I move down, it will disappear. But you look at ICD-10, which is the International Conference for Diseases, Classification of Diseases. And then we have things like SNOMED. This is all the systematic nomenclature of medicine. We also have for medication, RSNORM. So each of those entities that we detect for GERD here, we are also able to link them to all these different concepts, which give us a flexibility for the use cases that our customers are interested in. If there's a particular concept that they use in their business cases, then they just have to go find that abbreviation or that syntax and get a code. And then we also do relation extraction. So for instance, I hear that's a pulse. We identify that as a pulse. And that will give you, you go into the coding system. You'll give a definition for it. But we also see that we have a measurement value for it. And we have to extract that. And we build the relationship that says this is the value of the examination. We also see things that we also look at, things that are negated. So there's no weight loss. Even though the API will extract that as a symptom, we notice that in the text, there's no weight loss. We negate that. That is very critical for making a diagnosis when you're looking at unstructured text. So those are the four things that we do in the single API call to this endpoint. And then entity recognition. We do linking of the entity to known concepts or vocabularies. And then we also do relationship extraction between those entities and the attributes. And lastly, we do negation of those entities. This is so cool for me. I don't know if you know this. My first year of grad school, I took an NLP class. And our job was to go through emails of disease outbreaks and literally classify it. And then we also do that. I'm like, I'm looking at this here. I'm like tearing up a little bit. Because the way we used to do it was not this way. And this is pretty amazing. So a couple of questions about this. You mentioned that this is an API call. Do you have to use this interface? No, this is a visualization tool. Like I said, we originally announced this as a container that you can make an API call. The container would then be, you can download the container and deploy to any of your environments, whether it's on Azure or where it's local to your corporate environment. We realized that there was some challenge for some customers. So in a few weeks, in fact, in about 10 days, we'll be announcing the release of a hosted API. And I will switch now to the Postman to show you how the APIs can make a call. Let's do it. So here is a Postman setup. And this is making a call. Again, this is in local to my environment. Notice that the container is not HTTPS, but we can make this call to the similar kind of text. So in the body of your request, you can put up to, I believe, in the container up to a thousand documents. But again, even the more documents you stuff into the request body, it's going to take a while to process. But I'll take the same request body here to demonstrate the call, and I'll send it to my container, which is in the office somewhere, and it's going to take a while. So this is a synchronous call. So once you've made the request, you're going to wait for it to finish in order for you to get the result. What we will be releasing in 10 days is an asynchronous API. And that will allow you to send the request and forget it, and then come back and query the results of the request. So this right now, what you're seeing in Postman is the request to the container, which is synchronous. Again, you'll see that it will return all this output related for each entity that's detected. The text is the entity. All right, this is the symptom. And it shows you the different entities, different concepts that are linked to it. And then it also has a Boolean for negation. It's negated. If it's not, it's false. So this is the output from the container. What I'm going to show you is the output, what we're going to be doing, or be releasing on the 19. It is an endpoint. It's hosted. Ignore the string here because this is from the development environment. We're in the process of deploying the production right now. It takes a few days. So I'm going to send this request of the same body or same text to this API, this hosted API. Obviously, you've got to remember you've got to provision a text-anatic resource so you can get the key in order for you to authenticate to make the call. And again, I need to make a point of this. This public preview is still gated. It means you have to apply for access because we're trying to understand what are customers' use cases. And so when you apply for access, we can evaluate the use cases that you're going to use for and work with you to improve the service that you are interested in. So going back to this asynchronous API, this is the same request body that we sent you. We're going to make the call. And you can see that it will come back pretty quickly. Right now, it's back. It's back. But what you don't see is that in the headers, it will be a job ID. And that job ID basically is what you need to make a call to make a get call. And so what we did to submit this job is a post. So we do this, the get call and just paste, just extract, programmatically pull out the job ID, insert it at the end of the original API URL, and make the same call, a get call, sorry, not post. And then you will see the output. It's going to take a while to format it. Oh, there we go. You'll see that it will show you the date that was created and when the date the job was completed. More importantly, you see a status that it succeeded. So it allows you to be asynchronous while making the call, the request, and not have to worry about it, especially if you have a lot of documents and you don't want to be sitting there waiting for the synchronous response. And you can just forget about it and query and look for the status. The status will be still if it goes from started. I think I believe is processing. And sometimes if it fails, it will fail because you might exceed the number of characters per document. You can go up to a thousand. We're looking at optimizing that for a hosted endpoint. Then you will come back and say it succeeded. Once it succeeded, you will have the output that's shown here in the same output that we saw in the container. This is all very, very cool. So question, I know with health related stuff, there is this question of privacy. Can you talk about the way that this service protects customers' privacy? So first off, the request for the hosted API. So the whole container is within your own environment. You have control over how you protect your data. For the hosted API, we are a data processor. So we don't persist any of your information you sent to us. And because it's under Azure, you have all the benefits of Azure infrastructure with security, privacy, compliance. We are a HIPAA compliance, especially when we're talking about healthcare. So the information you sent to us, we would not persist them. What our telemetry will collect is just a number of documents. How many characters are in those documents? We don't persist any of the content that has been sent to us. And even if we, to the point where we can't help troubleshoot past a certain amount. Because this, what you see in the output here for this job, there is an expiration date, right? We do keep the results because we don't expect you to. But immediately you'll be done and you'll be pulling the results back. We will give you some time. And part of our policy is to persist this for 48 hours. And after that, it will be deleted. So once you, if you send a job to us and you keep checking, if you don't check within 48 hours, that job, the output will be completely deleted. So that we will be in compliance with our policies for privacy. This again is amazing. Ashley, where can people go to find out more? Yes, you can also go, you can find out more in the Azure document, Microsoft documentation site. I look for Connective Services, Text Analytics, and you'll find a section under Text Analytics for Health. And again, this is a public preview and it's gated right now. But there is a link in there to go to apply for access. If not, I can give the information to Seth and he will share it. That's right, we'll put it below. Well, Ashley, thank you so much for spending some time with us. And thank you so much for watching. We've been learning all about Text Analytics specifically for Health. Thank you so much for watching and hopefully we'll see you next time. Take care. We'll see you next time. Take care.